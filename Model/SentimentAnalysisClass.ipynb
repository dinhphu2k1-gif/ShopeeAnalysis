{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "SparkContext.setSystemProperty('spark.executor.memory', '4g')\n",
    "\n",
    "conf = SparkConf().setAppName(\"Process Comment\").setMaster(\"spark://25.15.27.228:7077\")\n",
    "sc = SparkContext.getOrCreate(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Process Comment').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self,sc,spark,load=False):\n",
    "        self.sc = sc\n",
    "        self.type = type\n",
    "        self.spark = spark\n",
    "        self.url = ['rate2_1/part-00000-2729185b-e28a-4984-b39e-86518549ec39-c000.snappy.parquet',\n",
    "        'rate2_2/part-00000-f47244d2-fc4d-4f67-a011-0a496be62822-c000.snappy.parquet',\n",
    "        'rate2_3/part-00000-dca5814a-b5ca-4ad4-b96c-b8b268c259a3-c000.snappy.parquet',\n",
    "        'rate2_4/part-00000-2de369cd-334e-4736-8e34-bd132d4b13ce-c000.snappy.parquet',\n",
    "        'rate2_5/part-00000-67e9e9c5-96e1-4619-8ae6-a4232c83df79-c000.snappy.parquet']\n",
    "        self.processData(load=load)\n",
    "        \n",
    "        \n",
    "    def processData(self,load=False):\n",
    "        df = []\n",
    "        for url in self.url:\n",
    "            tmp = self.spark.read.parquet(f'hdfs://cris:9000/ProcessShopee/Comment/{url}')\n",
    "            df.append(tmp.toPandas())\n",
    "\n",
    "        data = pd.concat(df,axis = 0)\n",
    "        data = data.reset_index(drop=True)\n",
    "        data.loc[data[data['rating_star'].astype(int) < 4].index, 'rating_star'] = 0\n",
    "        data.loc[data[data['rating_star'].astype(int) > 3].index, 'rating_star'] = 1\n",
    "        data.rating_star.value_counts()\n",
    "        data = self.spark.createDataFrame(data)\n",
    "        self.rawData = data\n",
    "        self.trainWord2vec(data,load=load)\n",
    "\n",
    "    def trainWord2vec(self,data,load=False):\n",
    "        from pyspark.ml.feature import Word2Vec\n",
    "        from pyspark.ml.feature import Word2VecModel\n",
    "        from pyspark.sql.functions import lower, col, split\n",
    "\n",
    "        dataset = data.select(lower(col('comment')).alias('comment'), 'rating_star')\n",
    "        dataset = dataset.select(split(dataset.comment, ' ').alias('comment'), 'rating_star')\n",
    "        self.splitData = dataset\n",
    "\n",
    "        if load:\n",
    "            model = Word2VecModel.load(f'hdfs://cris:9000/ProcessShopee/word2vec/')\n",
    "        else:\n",
    "            word2Vec = Word2Vec(vectorSize=100, seed=42, inputCol=\"comment\", outputCol=\"features\")\n",
    "            word2Vec.setMaxIter(5)\n",
    "            model = word2Vec.fit(dataset)\n",
    "\n",
    "        self.w2v = model\n",
    "\n",
    "        res = model.transform(dataset)\n",
    "        data = res.select('features', 'rating_star')\n",
    "        self.data = data.withColumnRenamed('rating_star', 'label')\n",
    "        self.featureData = self.data\n",
    "        splits = self.data.randomSplit([0.6, 0.4], 1234)\n",
    "\n",
    "        self.train_set = splits[0]\n",
    "        self.test_set = splits[1]\n",
    "    \n",
    "    def MPClassifier(self):\n",
    "        layers = [100, 120, 60, 2]\n",
    "        trainer = MultilayerPerceptronClassifier(maxIter=500, layers=layers, blockSize=128, seed=1234)\n",
    "        mpModel = trainer.fit(self.train_set)\n",
    "        result = mpModel.transform(self.test_set)\n",
    "        predictionAndLabels = result.select(\"prediction\", \"label\")\n",
    "        evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "        print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))\n",
    "        self.evaluate(predictionAndLabels,'MultilayerPerceptronClassifier')\n",
    "    \n",
    "    def OneRest(self):\n",
    "        from pyspark.ml.classification import LogisticRegression, OneVsRest\n",
    "        from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "        lr = LogisticRegression(maxIter=10, tol=1E-6, fitIntercept=True)\n",
    "        ovr = OneVsRest(classifier=lr)\n",
    "        ovrModel = ovr.fit(self.train_set)\n",
    "        predictions = ovrModel.transform(self.test_set)\n",
    "        evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "        accuracy = evaluator.evaluate(predictions)\n",
    "        print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "        self.evaluate(predictions,'LogisticRegression')\n",
    "\n",
    "\n",
    "    def svm(self):\n",
    "        from pyspark.ml import Pipeline\n",
    "        from pyspark.ml.classification import LinearSVC\n",
    "        from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "        from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "        labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(self.data)\n",
    "\n",
    "        featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(self.data)\n",
    "\n",
    "        (trainingData, testData) = self.data.randomSplit([0.7, 0.3])\n",
    "\n",
    "        svm = LinearSVC(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", maxIter=500)\n",
    "\n",
    "        labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=labelIndexer.labels)\n",
    "\n",
    "        pipeline = Pipeline(stages=[labelIndexer, featureIndexer, svm, labelConverter])\n",
    "\n",
    "        model = pipeline.fit(trainingData)\n",
    "        predictions = model.transform(testData)\n",
    "\n",
    "        evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "        accuracy = evaluator.evaluate(predictions)\n",
    "        print(\"Test accuracy = %g\" % (accuracy))\n",
    "\n",
    "        predictions = predictions.select('label', 'predictedLabel')\n",
    "        predictions = predictions.withColumnRenamed('predictedLabel', 'prediction')\n",
    "\n",
    "        self.evaluate(predictions, 'SVM')\n",
    "\n",
    "\n",
    "    def RandForest(self):\n",
    "        from pyspark.ml import Pipeline\n",
    "        from pyspark.ml.classification import RandomForestClassifier\n",
    "        from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "        from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "        labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(self.data)\n",
    "\n",
    "        featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(self.data)\n",
    "\n",
    "        (trainingData, testData) = self.data.randomSplit([0.7, 0.3])\n",
    "\n",
    "        rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=50)\n",
    "\n",
    "        labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=labelIndexer.labels)\n",
    "\n",
    "        pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
    "\n",
    "        model = pipeline.fit(trainingData)\n",
    "        predictions = model.transform(testData)\n",
    "\n",
    "        evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "        accuracy = evaluator.evaluate(predictions)\n",
    "        print(\"Test accuracy = %g\" % (accuracy))\n",
    "\n",
    "        predictions = predictions.select('label', 'predictedLabel')\n",
    "        predictions = predictions.withColumnRenamed('predictedLabel', 'prediction')\n",
    "\n",
    "        self.evaluate(predictions, 'random forest')\n",
    "\n",
    "\n",
    "    def evaluate(self,predictionAndLabels,model):\n",
    "        from sklearn.metrics import f1_score\n",
    "        from sklearn.metrics import precision_score\n",
    "        from sklearn.metrics import recall_score\n",
    "\n",
    "        res = predictionAndLabels.toPandas()\n",
    "        F1_score = f1_score(res.label, res.prediction.astype(int), average=None)\n",
    "        re_score = recall_score(res.label, res.prediction.astype(int), average=None)\n",
    "        pre_score = precision_score(res.label, res.prediction.astype(int), average=None)\n",
    "        print(f'F1 score {model}: {F1_score}')\n",
    "        print(f'Recall score {model}: {re_score}')\n",
    "        print(f'Precision score {model}: {pre_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model('sc',spark,load=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(comment='Thực_sự thất_vọng về sản_phẩm . Giao sai hàng , sai màu . Sp thì size M 40-50 kg , tôi 46kg mặc chỉ kéo qua đầu_gối . Vì ct16 nên k đi gơit trả hàng dc đành để làm dẻ lau nhà hoặc khăn lau cho chó nó tắm . Tức gì đâu', rating_star=0)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.rawData.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|             comment|rating_star|\n",
      "+--------------------+-----------+\n",
      "|[thực_sự, thất_vọ...|          0|\n",
      "|[hàng, nhận, đc, ...|          0|\n",
      "|[đặt, 1, đùi, và,...|          0|\n",
      "|[chất_liệu, quá, ...|          0|\n",
      "|[giao, vải, bị, l...|          0|\n",
      "|[mỏng, te, ko, nh...|          0|\n",
      "|[shop, cố_tình, g...|          0|\n",
      "|[shop, ngoài, cái...|          0|\n",
      "|[sản_phẩm, kém, c...|          0|\n",
      "|[mua, áo, áp_dụng...|          0|\n",
      "|[vải, xấu, đau_đớ...|          0|\n",
      "|    [vải, quá, mỏng]|          0|\n",
      "|[thất_vọng, tôi, ...|          0|\n",
      "|[mua, 2, tấm, lướ...|          0|\n",
      "|[quần, quá, xấu, ...|          0|\n",
      "|   [chất_lượng, kém]|          0|\n",
      "|[không, tốt, như,...|          0|\n",
      "|[em, đặt, 1, bộ, ...|          0|\n",
      "|[sản_phẩm, màu, k...|          0|\n",
      "|[rõ_ràng, không, ...|          0|\n",
      "+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.splitData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(features=DenseVector([-0.0174, 0.0119, -0.0421, 0.0937, -0.0235, 0.0302, -0.0108, 0.1426, -0.0875, -0.0354, 0.0298, 0.0618, -0.0105, 0.0405, 0.074, -0.1662, -0.0, -0.0401, -0.0495, -0.0587, 0.0345, 0.0278, 0.0095, -0.0296, -0.0126, -0.0084, 0.0205, -0.104, 0.0515, -0.01, 0.1015, 0.0005, -0.0456, -0.0379, 0.0126, -0.0638, 0.0156, 0.0262, 0.0282, -0.0609, 0.0096, -0.0718, 0.0583, 0.0148, -0.0804, -0.0509, -0.0327, 0.0548, 0.0534, -0.108, -0.0039, 0.0445, -0.0154, 0.1341, 0.0898, 0.0087, 0.0435, 0.0969, -0.0207, -0.0313, -0.0331, 0.1383, 0.0197, 0.2204, -0.0663, 0.0579, 0.0899, -0.0049, -0.0502, -0.0252, -0.1318, -0.0085, -0.0929, -0.0255, 0.0261, -0.0186, -0.0556, 0.0023, 0.1293, 0.0985, -0.0403, -0.0169, -0.0192, -0.0478, 0.0098, -0.0043, 0.0091, -0.0087, 0.075, -0.0176, 0.1849, -0.0018, 0.0272, -0.078, -0.1213, -0.0142, -0.0635, -0.0377, 0.0709, 0.0107]), label=0)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.featureData.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.w2v.save(f'hdfs://cris:9000/ProcessShopee/word2vec/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.9311043031913815\n",
      "F1 score MultilayerPerceptronClassifier: [0.58501772 0.96243376]\n",
      "Recall score MultilayerPerceptronClassifier: [0.49723711 0.97806418]\n",
      "Precision score MultilayerPerceptronClassifier: [0.71043571 0.94729507]\n"
     ]
    }
   ],
   "source": [
    "model.MPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.0771612\n",
      "F1 score LogisticRegression: [0.49589099 0.95822202]\n",
      "Recall score LogisticRegression: [0.38859113 0.98066338]\n",
      "Precision score LogisticRegression: [0.6850509  0.93678477]\n"
     ]
    }
   ],
   "source": [
    "model.OneRest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.922033\n",
      "F1 score SVM: [0.43766361 0.95811276]\n",
      "Recall score SVM: [0.31239891 0.98761062]\n",
      "Precision score SVM: [0.73062875 0.93032588]\n"
     ]
    }
   ],
   "source": [
    "model.svm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.902453\n",
      "F1 score random forest: [0.        0.9487259]\n",
      "Recall score random forest: [0. 1.]\n",
      "Precision score random forest: [0.         0.90245342]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dqp/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model.RandForest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+\n",
      "|label|number_samples|\n",
      "+-----+--------------+\n",
      "|    0|         59930|\n",
      "|    1|        556311|\n",
      "+-----+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.data.createOrReplaceTempView(\"data\")\n",
    "spark.sql(\"select label, count(label) as number_samples from data group by label order by count(label)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+\n",
      "|label|number_samples|\n",
      "+-----+--------------+\n",
      "|    0|         35861|\n",
      "|    1|        333935|\n",
      "+-----+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.train_set.createOrReplaceTempView(\"train\")\n",
    "spark.sql(\"select label, count(label) as number_samples from train group by label order by count(label)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+\n",
      "|label|number_samples|\n",
      "+-----+--------------+\n",
      "|    0|         24069|\n",
      "|    1|        222376|\n",
      "+-----+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.test_set.createOrReplaceTempView(\"test\")\n",
    "spark.sql(\"select label, count(label) as number_samples from test group by label order by count(label)\").show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
