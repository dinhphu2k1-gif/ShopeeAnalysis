{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "SparkContext.setSystemProperty('spark.executor.memory', '3g')\n",
    "conf = SparkConf().setAppName(\"Process Comment\").setMaster(\"spark://25.15.27.228:7077\")\n",
    "sc = SparkContext.getOrCreate(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Process Comment').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self,sc,spark):\n",
    "        self.sc = sc\n",
    "        self.type = type\n",
    "        self.spark = spark\n",
    "        # self.URI           = self.sc._gateway.jvm.java.net.URI\n",
    "        # self.Path          = self.sc._gateway.jvm.org.apache.hadoop.fs.Path\n",
    "        # self.FileSystem    = self.sc._gateway.jvm.org.apache.hadoop.fs.FileSystem\n",
    "        # self.Configuration = self.sc._gateway.jvm.org.apache.hadoop.conf.Configuration\n",
    "        self.url = ['rate2_1/part-00000-2729185b-e28a-4984-b39e-86518549ec39-c000.snappy.parquet',\n",
    "        'rate2_2/part-00000-f47244d2-fc4d-4f67-a011-0a496be62822-c000.snappy.parquet',\n",
    "        'rate2_3/part-00000-dca5814a-b5ca-4ad4-b96c-b8b268c259a3-c000.snappy.parquet',\n",
    "        'rate2_4/part-00000-2de369cd-334e-4736-8e34-bd132d4b13ce-c000.snappy.parquet',\n",
    "        'rate2_5/part-00000-67e9e9c5-96e1-4619-8ae6-a4232c83df79-c000.snappy.parquet']\n",
    "        # self.processData()\n",
    "        \n",
    "        \n",
    "    def processData(self):\n",
    "        df = []\n",
    "        for url in self.url:\n",
    "            tmp = self.spark.read.parquet(f'hdfs://cris:9000/ProcessShopee/Comment/{url}')\n",
    "            df.append(tmp.toPandas())\n",
    "\n",
    "        data = pd.concat(df,axis = 0)\n",
    "        data = data.reset_index(drop=True)\n",
    "        data.loc[data[data['rating_star'].astype(int) < 4].index, 'rating_star'] = 0\n",
    "        data.loc[data[data['rating_star'].astype(int) > 3].index, 'rating_star'] = 1\n",
    "        data.rating_star.value_counts()\n",
    "        data = self.spark.createDataFrame(data)\n",
    "        self.trainWord2vec(data)\n",
    "\n",
    "    def trainWord2vec(self,data):\n",
    "        from pyspark.ml.feature import Word2Vec\n",
    "        from pyspark.sql.functions import lower, col, split\n",
    "\n",
    "        dataset = data.select(lower(col('comment')).alias('comment'), 'rating_star')\n",
    "        dataset = dataset.select(split(dataset.comment, ' ').alias('comment'), 'rating_star')\n",
    "\n",
    "        word2Vec = Word2Vec(vectorSize=100, seed=42, inputCol=\"comment\", outputCol=\"features\")\n",
    "        word2Vec.setMaxIter(5)\n",
    "        model = word2Vec.fit(dataset)\n",
    "\n",
    "        res = model.transform(dataset)\n",
    "        data = res.select('features', 'rating_star')\n",
    "        data = data.withColumnRenamed('rating_star', 'label')\n",
    "        splits = data.randomSplit([0.6, 0.4], 1234)\n",
    "\n",
    "        self.train_set = splits[0]\n",
    "        self.test_set = splits[1]\n",
    "    \n",
    "    def MPClassifier(self):\n",
    "        layers = [100, 120, 60, 2]\n",
    "        trainer = MultilayerPerceptronClassifier(maxIter=500, layers=layers, blockSize=128, seed=1234)\n",
    "        mpModel = trainer.fit(self.train_set)\n",
    "        result = mpModel.transform(self.test_set)\n",
    "        predictionAndLabels = result.select(\"prediction\", \"label\")\n",
    "        evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "        print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))\n",
    "        self.evaluate(predictionAndLabels,'MultilayerPerceptronClassifier')\n",
    "    \n",
    "    def OneRest(self):\n",
    "        from pyspark.ml.classification import LogisticRegression, OneVsRest\n",
    "        from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "        lr = LogisticRegression(maxIter=10, tol=1E-6, fitIntercept=True)\n",
    "        ovr = OneVsRest(classifier=lr)\n",
    "        ovrModel = ovr.fit(self.train_set)\n",
    "        predictions = ovrModel.transform(self.test_set)\n",
    "        evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "        accuracy = evaluator.evaluate(predictions)\n",
    "        print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "        self.evaluate(predictions,'LogisticRegression')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def evaluate(self,predictionAndLabels,model):\n",
    "        from sklearn.metrics import f1_score\n",
    "        from sklearn.metrics import precision_score\n",
    "        from sklearn.metrics import recall_score\n",
    "\n",
    "        res = predictionAndLabels.toPandas()\n",
    "        f1_score = f1_score(res.label, res.prediction.astype(int), average=None)\n",
    "        re_score = recall_score(res.label, res.prediction.astype(int), average=None)\n",
    "        pre_score = precision_score(res.label, res.prediction.astype(int), average=None)\n",
    "        print(f'F1 score {model}: {f1_score}')\n",
    "        print(f'Recall score {model}: {re_score}')\n",
    "        print(f'Precision score {model}: {pre_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model('sc',spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.8192122567961494\n",
      "F1 score MultilayerPerceptronClassifier: [0.71083449 0.86849839]\n",
      "Recall score MultilayerPerceptronClassifier: [0.68114376 0.8860627 ]\n",
      "Precision score MultilayerPerceptronClassifier: [0.7432316 0.8516169]\n"
     ]
    }
   ],
   "source": [
    "model.MPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.OneRest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
