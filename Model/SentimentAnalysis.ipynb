{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Word2Vec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "SparkContext.setSystemProperty('spark.executor.memory', '3g')\n",
    "conf = SparkConf().setAppName(\"Process Comment\").setMaster(\"spark://25.15.27.228:7077\")\n",
    "sc = SparkContext.getOrCreate(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Process Comment').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'hdfs://cris:9000/ProcessShopee/Comment/rate_sum/part-00000-2bb5d99d-0093-4c2e-bc46-0b8487d2c0db-c000.snappy.parquet'\n",
    "data = spark.read.parquet(url)\n",
    "data = data.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data[data['rating_star'].astype(int) < 4].index, 'rating_star'] = 0\n",
    "data.loc[data[data['rating_star'].astype(int) > 3].index, 'rating_star'] = 1\n",
    "data.rating_star.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.createDataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.sql.functions import lower, col, split\n",
    "\n",
    "dataset = data.select(lower(col('comment')).alias('comment'), 'rating_star')\n",
    "dataset = dataset.select(split(dataset.comment, ' ').alias('comment'), 'rating_star')\n",
    "\n",
    "word2Vec = Word2Vec(vectorSize=100, seed=42, inputCol=\"comment\", outputCol=\"features\")\n",
    "word2Vec.setMaxIter(5)\n",
    "model = word2Vec.fit(dataset)\n",
    "\n",
    "res = model.transform(dataset)\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = res.select('features', 'rating_star')\n",
    "data = data.withColumnRenamed('rating_star', 'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **MultilayerPerceptronClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "#split train test\n",
    "(train, test) = data.randomSplit([0.6, 0.4], 1234)\n",
    "\n",
    "layers = [100, 120, 60, 2]\n",
    "# create the trainer and set its parameters\n",
    "trainer = MultilayerPerceptronClassifier(maxIter=500, layers=layers, blockSize=128, seed=1234)\n",
    "\n",
    "# train the model\n",
    "model = trainer.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute accuracy on the test set\n",
    "result = model.transform(test)\n",
    "predictionAndLabels = result.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "res_pred = res_pred = predictionAndLabels.toPandas()\n",
    "\n",
    "f1 = f1_score(res_pred.label, res_pred.prediction.astype(int), average=None)\n",
    "precision = precision_score(res_pred.label, res_pred.prediction.astype(int), average=None)\n",
    "recall = recall_score(res_pred.label, res_pred.prediction.astype(int), average=None)\n",
    "\n",
    "print('Label: \\t \\t    0   \\t    1')\n",
    "print('F1 score: \\t {:.5f}  \\t {:.5f}'.format(f1[0], f1[1]))\n",
    "print('Precision: \\t {:.5f}  \\t {:.5f}'.format(precision[0], precision[1]))\n",
    "print('Recall: \\t {:.5f}  \\t {:.5f}'.format(recall[0], recall[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ramdom Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
    "\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=50)\n",
    "\n",
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=labelIndexer.labels)\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "res_pred = predictions.select(\"predictedLabel\", \"label\").toPandas()\n",
    "\n",
    "f1 = f1_score(res_pred.label, res_pred.prediction.astype(int), average=None)\n",
    "precision = precision_score(res_pred.label, res_pred.prediction.astype(int), average=None)\n",
    "recall = recall_score(res_pred.label, res_pred.prediction.astype(int), average=None)\n",
    "\n",
    "print('Label: \\t \\t    0   \\t    1')\n",
    "print('F1 score: \\t {:.5f}  \\t {:.5f}'.format(f1[0], f1[1]))\n",
    "print('Precision: \\t {:.5f}  \\t {:.5f}'.format(precision[0], precision[1]))\n",
    "print('Recall: \\t {:.5f}  \\t {:.5f}'.format(recall[0], recall[1]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
